import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import matplotlib.pyplot as plt
import json
from models.CCViM_fusion_vnet import CCViMFusionVNet
from mydatasets.brain_dataset import BrainDataset
from loss_function import SegmentationLoss
from metrics import compute_all_metrics
import matplotlib.colors as mcolors
import numpy as np
import os
from mydatasets.transforms import NormalizePETto255
import h5py
import json
from collections import defaultdict

try:
    import colorcet as cc

    has_cc = True
except ImportError:
    has_cc = False


def generate_distinct_colors(n):
    """ç”Ÿæˆ n ç§é«˜åŒºåˆ†åº¦é¢œè‰²ï¼ˆèƒŒæ™¯ä¸ºé»‘è‰²ï¼‰"""
    if has_cc and n > 1:
        base_colors = cc.glasbey[:n - 1]
    else:
        base_colors = plt.cm.hsv(np.linspace(0, 1, n - 1))
    return ["black"] + list(base_colors)


# ------------------------------------------
# å¯è§†åŒ–é¢„æµ‹å‡½æ•°
# ------------------------------------------
torch.no_grad()


def visualize_prediction(model, dataset, device, epoch, save_dir,
                         color_map_path="./data/class_color_map_0_200.json"):
    """
    éšæœºé€‰æ‹©ä¸€å¼ æ ·æœ¬ï¼Œä¿å­˜ T1 + PET + Prior + Pred + GT å¯¹æ¯”å›¾
    ä½¿ç”¨å¤–éƒ¨JSONé¢œè‰²æ˜ å°„æ–‡ä»¶ï¼ˆ0å›ºå®šä¸ºé»‘è‰²ï¼‰
    """
    os.makedirs(save_dir, exist_ok=True)
    model.eval()

    # === åŠ è½½é¢œè‰²æ˜ å°„è¡¨ ===
    with open(color_map_path, "r") as f:
        color_dict = json.load(f)

    # å°†å­—ç¬¦ä¸²hexè½¬ä¸ºmatplotlibå¯ç”¨çš„RGBåˆ—è¡¨
    max_class = max(map(int, color_dict.keys()))
    color_list = [color_dict[str(i)] if str(i) in color_dict else "#000000" for i in range(max_class + 1)]
    cmap_fixed = mcolors.ListedColormap(color_list)
    norm_fixed = mcolors.BoundaryNorm(np.arange(max_class + 2) - 0.5, cmap_fixed.N)

    # === éšæœºæŠ½æ · ===
    idx = torch.randint(0, len(dataset), (1,)).item()
    sample = dataset[idx]

    # === æ•°æ®å‡†å¤‡ ===
    t1 = sample["t1"].unsqueeze(0).to(device)
    pet = sample["pet"].unsqueeze(0).to(device)
    prior = sample["sam_prior"].unsqueeze(0).to(device)
    gt = sample["gt"].squeeze().cpu().numpy()

    # === æ¨¡å‹é¢„æµ‹ ===
    output = model(t1, pet, prior)
    output = torch.softmax(output, dim=1).detach().squeeze().cpu().numpy()

    # === GT / PRIOR / PRED è½¬ä¸ºç±»åˆ«å›¾ ===
    gt_mask = np.argmax(gt, axis=0)
    prior_mask = prior.squeeze().cpu().numpy()
    pred_mask = np.argmax(output, axis=0)

    # === åŸå§‹T1ã€PETå½±åƒ ===
    t1_img = t1.squeeze().cpu().numpy()
    if t1_img.ndim == 3:
        t1_img = np.mean(t1_img, axis=0)

    pet_img = pet.squeeze().cpu().numpy()
    if pet_img.ndim == 3:
        pet_img = np.mean(pet_img, axis=0)

    # === å±è”½èƒŒæ™¯ ===
    masked_prior = np.ma.masked_where(prior_mask == 0, prior_mask)
    masked_pred = np.ma.masked_where(pred_mask == 0, pred_mask)
    masked_gt = np.ma.masked_where(gt_mask == 0, gt_mask)

    # === ç»˜å›¾ï¼š2è¡Œ3åˆ— ===
    fig, axs = plt.subplots(2, 3, figsize=(18, 9))

    # ç¬¬ä¸€è¡Œï¼šåŸå§‹è¾“å…¥
    axs[0, 0].imshow(t1_img, cmap="gray", origin="lower")
    axs[0, 0].set_title(f"T1 Image (idx={idx})")
    axs[0, 0].axis("off")

    axs[0, 1].imshow(pet_img, cmap="gray", origin="lower")
    axs[0, 1].set_title("PET Image")
    axs[0, 1].axis("off")

    axs[0, 2].axis("off")

    # ç¬¬äºŒè¡Œï¼šPrior / Pred / GT
    axs[1, 0].imshow(t1_img, cmap="gray", origin="lower")
    im_prior = axs[1, 0].imshow(masked_prior, cmap=cmap_fixed, norm=norm_fixed, alpha=0.5, origin="lower")
    axs[1, 0].set_title("T1 + Prior")
    axs[1, 0].axis("off")

    axs[1, 1].imshow(t1_img, cmap="gray", origin="lower")
    im_pred = axs[1, 1].imshow(masked_pred, cmap=cmap_fixed, norm=norm_fixed, alpha=0.5, origin="lower")
    axs[1, 1].set_title("T1 + Predicted Segmentation")
    axs[1, 1].axis("off")

    axs[1, 2].imshow(t1_img, cmap="gray", origin="lower")
    im_gt = axs[1, 2].imshow(masked_gt, cmap=cmap_fixed, norm=norm_fixed, alpha=0.5, origin="lower")
    axs[1, 2].set_title("Ground Truth Mask")
    axs[1, 2].axis("off")

    # === æ·»åŠ é¢œè‰²æ¡ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡å³å¯ï¼‰ ===
    cbar = plt.colorbar(im_gt, ax=axs[1, 2], fraction=0.046, pad=0.04)
    cbar.set_label("Class ID", rotation=270, labelpad=10)

    plt.tight_layout()
    save_path = os.path.join(save_dir, f"epoch_{epoch}_sample_{idx}.png")
    plt.savefig(save_path, dpi=200)
    plt.close(fig)

    print(f"[Visualize] Epoch {epoch} sample {idx} saved to {save_path}")


# ------------------------------------------
# éªŒè¯å¾ªç¯ï¼ˆä¿®æ”¹ç‰ˆï¼‰
# ------------------------------------------
def validate(model, loader, loss_fn, device, save_dir):
    model.eval()

    # æ¯ä¸ªæ ·æœ¬ç»“æœ
    sample_results = []

    # ç»Ÿè®¡æ€»æŒ‡æ ‡
    total = defaultdict(float)
    count = 0

    # h5 æ–‡ä»¶å­˜é¢„æµ‹è¾“å‡º
    h5_path = os.path.join(save_dir, "outputs.h5")
    h5_file = h5py.File(h5_path, "w")

    with torch.no_grad():
        for batch in tqdm(loader, desc="Val", leave=False):
            t1 = batch["t1"].to(device)
            pet = batch["pet"].to(device)
            prior = batch["sam_prior"].to(device)
            gt = batch["gt"].to(device)
            meta = batch["meta"]  # å…³é”®å­—æ®µï¼ˆlistï¼‰

            outputs = model(t1,pet,prior)
            loss = loss_fn(outputs, gt)
            metrics = compute_all_metrics(outputs, gt)

            B = t1.shape[0]
            preds = torch.argmax(outputs, dim=1).cpu().numpy()

            for b in range(B):
                sample_name = meta['h5'][b]

                # ä¿å­˜é¢„æµ‹ mask åˆ° H5
                grp = h5_file.create_group(sample_name)
                grp.create_dataset("pred", data=preds[b], compression="gzip")

                # ä¿å­˜æŒ‡æ ‡
                result_dict = {
                    "meta": sample_name,
                    "loss": float(loss.item()),
                }
                result_dict.update({k: float(metrics[k]) for k in metrics})
                sample_results.append(result_dict)

                # ç´¯åŠ 
                for k in metrics:
                    total[k] += float(metrics[k])
                total["loss"] += float(loss.item())
                count += 1

    h5_file.close()

    # è®¡ç®—å¹³å‡
    avg_results = {k: total[k] / count for k in total}

    return sample_results, avg_results


# ------------------------------------------
# è®­ç»ƒä¸»å‡½æ•°
# ------------------------------------------
def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    transform = NormalizePETto255()
    model_name = "our_big"

    # ä¿å­˜ç›®å½•
    save_dir = f"./trains/eval_result/{model_name}"
    os.makedirs(save_dir, exist_ok=True)

    val_set = BrainDataset(
        "./data/val_samples_clean.json",
        "./data/GT_class_stats_dlmuse.json",
        "./data/GT_class_stats_mask.json",
        transform=transform,
    )

    val_loader = DataLoader(val_set, batch_size=8, shuffle=False, num_workers=4)

    model = CCViMFusionVNet().to(device)

    loss_fn = SegmentationLoss()

    pretrained_path = "./trains/checkpoints/CCViMFusionVNet_big/epoch_30.pth"
    if os.path.exists(pretrained_path):
        print(f"âœ… Loading pretrained model from: {pretrained_path}")
        model.load_state_dict(torch.load(pretrained_path, map_location=device))

        sample_results, avg_results = validate(model, val_loader, loss_fn, device, save_dir)

    # ä¿å­˜ sample-wise ç»“æœ
    json.dump(sample_results, open(os.path.join(save_dir, "eval_samples.json"), "w"), indent=2)

    # ä¿å­˜å¹³å‡ç»“æœ
    json.dump(avg_results, open(os.path.join(save_dir, "eval_avg.json"), "w"), indent=2)

    print("\n===== âœ… Evaluation Finished =====")
    print(f"ğŸ“Œ Sample results: {save_dir}/eval_samples.json")
    print(f"ğŸ“Œ Average results: {save_dir}/eval_avg.json")
    print(f"ğŸ“Œ Predictions saved: {save_dir}/outputs.h5\n")

    print(
        f"Avg Loss: {avg_results['loss']:.4f} | "
        f"Dice: {avg_results['dice']:.4f} | "
        f"IoU: {avg_results['iou']:.4f} | "
        f"mIoU: {avg_results['miou']:.4f} | "
        f"HD: {avg_results['hausdorff']:.1f}"
    )


if __name__ == "__main__":
    main()
